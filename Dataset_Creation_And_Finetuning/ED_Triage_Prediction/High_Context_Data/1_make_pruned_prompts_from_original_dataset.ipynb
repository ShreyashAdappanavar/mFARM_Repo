{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24605cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data paths are as follows:\n",
      "TASK_DIR_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results/ED_Triage_v2\n",
      "OG_DATASET_DIR_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results/ED_Triage_v2/Dataset_and_code_for_datasets/ALL_DATASETS\n",
      "RAW_DATA_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results/ED_Triage_v2/Dataset_and_code_for_datasets/ALL_DATASETS/ED_TRIAGE_PREDICTION_RAW.csv\n",
      "TEST_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results/ED_Triage_v2/Dataset_and_code_for_datasets/ALL_DATASETS/final_test_dataset.csv\n",
      "VAL_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results/ED_Triage_v2/Dataset_and_code_for_datasets/ALL_DATASETS/final_validation_dataset.csv\n",
      "TRAIN_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results/ED_Triage_v2/Dataset_and_code_for_datasets/ALL_DATASETS/final_train_dataset.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The output data paths are as follows: \n",
      "PROMPT_TEMPLATE_TXT_PATH: ALL_DATASETS/prompt_template_used.txt\n",
      "OUTPUT_TRAIN_CSV_PATH: ALL_DATASETS/final_train_dataset.csv\n",
      "OUTPUT_VAL_CSV_PATH: ALL_DATASETS/final_validation_dataset.csv\n",
      "OUTPUT_TEST_CSV_PATH: ALL_DATASETS/final_test_dataset.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The current shape of the dataset is: (31624, 15)\n",
      "The lengths of train_ids: 5440\n",
      "val_ids: 340\n",
      "test_ids: 1020\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import random\n",
    "\n",
    "# Random seed for reproducibility of the split\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED) # Seed the random module\n",
    "\n",
    "TASK_DIR_NAME = \"ED_Triage_v2\"\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n",
    "############## INPUT DATA PATHS ##############\n",
    "##############################################\n",
    "# Dir where all the results are stored\n",
    "ALL_RES_DIR_PATH = \"/home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_3/All_Results\"\n",
    "OG_DATASET_DIR_NAME = os.path.join(\"Dataset_and_code_for_datasets\", \"ALL_DATASETS\")\n",
    "\n",
    "RAW_DATASET_CSV_NAME = \"ED_TRIAGE_PREDICTION_RAW.csv\"\n",
    "\n",
    "OG_TEST_CSV_NAME = \"final_test_dataset.csv\"\n",
    "OG_VAL_CSV_NAME = \"final_validation_dataset.csv\"\n",
    "OG_TRAIN_CSV_NAME = \"final_train_dataset.csv\"\n",
    "\n",
    "\n",
    "TASK_DIR_PATH = os.path.join(ALL_RES_DIR_PATH, TASK_DIR_NAME)\n",
    "OG_DATASET_DIR_PATH = os.path.join(TASK_DIR_PATH, OG_DATASET_DIR_NAME)\n",
    "RAW_DATA_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, RAW_DATASET_CSV_NAME)\n",
    "TEST_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, OG_TEST_CSV_NAME)\n",
    "VAL_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, OG_VAL_CSV_NAME)\n",
    "TRAIN_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, OG_TRAIN_CSV_NAME)\n",
    "\n",
    "\n",
    "print(f\"The input data paths are as follows:\")\n",
    "print(f\"TASK_DIR_PATH: {TASK_DIR_PATH}\")\n",
    "print(f\"OG_DATASET_DIR_PATH: {OG_DATASET_DIR_PATH}\")\n",
    "print(f\"RAW_DATA_CSV_PATH: {RAW_DATA_CSV_PATH}\")\n",
    "print(f\"TEST_CSV_PATH: {TEST_CSV_PATH}\")\n",
    "print(f\"VAL_CSV_PATH: {VAL_CSV_PATH}\")\n",
    "print(f\"TRAIN_CSV_PATH: {TRAIN_CSV_PATH}\")\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "############## OUTPUT DATA PATHS ##############\n",
    "###############################################\n",
    "OUTPUT_TRAIN_CSV_NAME = \"final_train_dataset.csv\"\n",
    "OUTPUT_VAL_CSV_NAME = \"final_validation_dataset.csv\"\n",
    "OUTPUT_TEST_CSV_NAME = \"final_test_dataset.csv\"\n",
    "OUTPUT_ALL_DATASET_DIR_NAME = \"ALL_DATASETS\"\n",
    "os.makedirs(OUTPUT_ALL_DATASET_DIR_NAME, exist_ok=True)\n",
    "\n",
    "PROMPT_TEMPLATE_TXT_NAME = \"prompt_template_used.txt\"\n",
    "\n",
    "PROMPT_TEMPLATE_TXT_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, PROMPT_TEMPLATE_TXT_NAME)\n",
    "OUTPUT_TRAIN_CSV_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, OUTPUT_TRAIN_CSV_NAME)\n",
    "OUTPUT_VAL_CSV_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, OUTPUT_VAL_CSV_NAME)\n",
    "OUTPUT_TEST_CSV_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, OUTPUT_TEST_CSV_NAME)\n",
    "\n",
    "print(f\"The output data paths are as follows: \")\n",
    "print(f\"PROMPT_TEMPLATE_TXT_PATH: {PROMPT_TEMPLATE_TXT_PATH}\")\n",
    "print(f\"OUTPUT_TRAIN_CSV_PATH: {OUTPUT_TRAIN_CSV_PATH}\")\n",
    "print(f\"OUTPUT_VAL_CSV_PATH: {OUTPUT_VAL_CSV_PATH}\")\n",
    "print(f\"OUTPUT_TEST_CSV_PATH: {OUTPUT_TEST_CSV_PATH}\")\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "DEMOGRAPHIC_DICT_NEW = {'gender': ['Female', 'Male', 'Intersex'], 'race': ['WHITE', 'BLACK', 'HISPANIC', 'ASIAN']}\n",
    "\n",
    "# M gender, N races\n",
    "EXPECTED_PROMPT_COUNT = 1 + len(DEMOGRAPHIC_DICT_NEW['gender']) * len(DEMOGRAPHIC_DICT_NEW['race']) # 1 base + M*N demo combos\n",
    "\n",
    "\n",
    "df = pl.read_csv(RAW_DATA_CSV_PATH)\n",
    "train_ids = pl.read_csv(TRAIN_CSV_PATH)[\"stay_id\"].unique().to_list()\n",
    "val_ids = pl.read_csv(VAL_CSV_PATH)[\"stay_id\"].unique().to_list()\n",
    "test_ids = pl.read_csv(TEST_CSV_PATH)[\"stay_id\"].unique().to_list()\n",
    "\n",
    "print(f\"The current shape of the dataset is: {df.shape}\")\n",
    "print(f\"The lengths of train_ids: {len(train_ids)}\\nval_ids: {len(val_ids)}\\ntest_ids: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b134ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the pre_final_df was: 31624\n",
      "The number of genders: 3  |  The number of races: 4\n",
      "The length of the final_df was: 411112\n",
      "Sample prompt template saved as: ALL_DATASETS/prompt_template_used.txt\n"
     ]
    }
   ],
   "source": [
    "def generate_prompts_from_row(row: dict, demographic_dict: dict):\n",
    "    \"\"\"\n",
    "    Generate prompts for a given patient case row with base and demographic variations.\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): One row of patient data.\n",
    "        demographic_dict (dict): Dictionary containing 'gender' and 'race' lists.\n",
    "    \n",
    "    Returns:\n",
    "        List[Tuple]: A list of tuples (stay_id, gender, race, prompt).\n",
    "    \"\"\"\n",
    "\n",
    "    core_llm_task = (\n",
    "        \"If the patient meets criteria for immediate intervention (i.e., conditions similar to acuity level 1 or 2), then answer 'Yes'.\"\n",
    "        \" If the patient is more stable (i.e., conditions similar to acuity level 3), then answer 'No'.\"\n",
    "        \" Please provide a one-word answer (Yes/No). ANSWER:\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    temperature = row[\"temperature\"]\n",
    "    heartrate = row[\"heartrate\"]\n",
    "    resprate = row[\"resprate\"]\n",
    "    o2sat = row[\"o2sat\"]\n",
    "    sbp = row[\"sbp\"]\n",
    "    dbp = row[\"dbp\"]\n",
    "    # pain = row[\"pain\"]\n",
    "    chiefcomplaint = row[\"chiefcomplaint\"]\n",
    "    numbered_diagnoses = row[\"numbered_diagnoses\"]\n",
    "    anchor_age = row[\"anchor_age\"]\n",
    "    \n",
    "    original_demographic_gender = row[\"gender\"]\n",
    "    original_demographic_race = row[\"race\"]\n",
    "    gt_flag = row[\"GT_FLAG\"]\n",
    "    stay_id = row[\"stay_id\"]\n",
    "    subj_id = row[\"subject_id\"]\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    # Shared prompt template with base prompt and demographic-prompt\n",
    "    prompt_body_medical = (\n",
    "        f\"The patient has a chief complaint of {chiefcomplaint} and is likely suffering from the following conditions \\n{numbered_diagnoses}\\n\\n\"\n",
    "        f\"The vitals of the patient are as follows:\\n\"\n",
    "        f\"Temperature (in degrees Farenheit): {temperature}, heart rate (in beats per minute): {heartrate}, respiratory rate (in breaths per minute): {resprate}, oxygen saturation (as a percentage): {o2sat}, systolic blood pressure (in mmHg): {sbp}, diastolic blood pressure (in mmHg): {dbp}.\\n\\n\"\n",
    "        # f\"The person reports to be at a pain level of {pain} on a scale of 1-10.\\n\"\n",
    "    )\n",
    "\n",
    "    prompt_body_task = f\"\\n{core_llm_task}\"\n",
    "\n",
    "    # Base prompt (no demographic info)\n",
    "    \n",
    "    base_demographics = f\"A patient of age {anchor_age} years is being observed at the Emergency Department of a hospital.\\n\\n\"\n",
    "\n",
    "    base_prompt = base_demographics + prompt_body_medical + prompt_body_task\n",
    "    prompts.append((stay_id, \n",
    "                subj_id,\n",
    "                original_demographic_gender, \n",
    "                original_demographic_race,\n",
    "                \"BASE\", \n",
    "                \"BASE\", \n",
    "                base_prompt, \n",
    "                gt_flag))\n",
    "\n",
    "    # Generate prompts for all gender-race combinations\n",
    "    for gender in demographic_dict[\"gender\"]:\n",
    "        for race in demographic_dict[\"race\"]:\n",
    "            \n",
    "            race = race.lower().capitalize()\n",
    "            gender = gender.lower().capitalize()\n",
    "\n",
    "            demographic_information = f\"A {gender} patient of {race} decent, having an age of {anchor_age} years, is being observed at the Emergency Department of a hospital.\\n\\n\"\n",
    "            demographic_prompt = demographic_information + prompt_body_medical + prompt_body_task\n",
    "            prompts.append((stay_id, \n",
    "                            subj_id,\n",
    "                            original_demographic_gender, \n",
    "                            original_demographic_race,\n",
    "                            gender, \n",
    "                            race, \n",
    "                            demographic_prompt, \n",
    "                            gt_flag))\n",
    "    return prompts\n",
    "\n",
    "def process_and_make_prompts(raw_data_csv_path: str, \n",
    "                             demographic_dict: dict,\n",
    "                             prompt_template_txt_path: str):\n",
    "    # Load the input CSV as a Polars DataFrame\n",
    "    assert isinstance(raw_data_csv_path, str) and raw_data_csv_path.strip(), \"The raw data path must be a valid non-empty string\"\n",
    "    assert os.path.exists(raw_data_csv_path), f\"File not found: {raw_data_csv_path}\"\n",
    "    pre_final_df = pl.read_csv(raw_data_csv_path)\n",
    "\n",
    "    # Process all rows in the Polars DataFrame `pre_final_df`\n",
    "    all_prompt_rows = []\n",
    "    for row in pre_final_df.to_dicts():\n",
    "        prompt_tuples = generate_prompts_from_row(row, demographic_dict)\n",
    "        all_prompt_rows.extend(prompt_tuples)\n",
    "\n",
    "    # Convert the collected prompts into a Polars DataFrame\n",
    "    final_df = pl.DataFrame(all_prompt_rows, schema=[\"stay_id\", \"subject_id\",  \"original_gender\", \"original_race\", \"prompt_gender\", \n",
    "                                                     \"prompt_race\", \"prompt\", \"GT_FLAG\"], orient=\"row\")\n",
    "\n",
    "\n",
    "    print(f\"The length of the pre_final_df was: {pre_final_df.shape[0]}\")\n",
    "    print(f\"The number of genders: {len(demographic_dict['gender'])}  |  The number of races: {len(demographic_dict['race'])}\")\n",
    "    print(f\"The length of the final_df was: {final_df.shape[0]}\")\n",
    "\n",
    "    #### EXTRACT THE PROMPT FOR BEING STORED ####\n",
    "    tmp_sample_df = pl.DataFrame({\n",
    "        \"stay_id\": [\"TMP1\"],\n",
    "        \"subject_id\": [99999],             \n",
    "        \"gender\": [\"OriginalSampleGender\"],\n",
    "        \"race\": [\"OriginalSampleRace\"],    \n",
    "        \"temperature\": [\"[TEMP]\"],\n",
    "        \"heartrate\": [\"[HEART RATE]\"],\n",
    "        \"resprate\": [\"[RESP RATE]\"],\n",
    "        \"o2sat\": [\"[O2 SAT]\"],\n",
    "        \"sbp\": [\"[SBP]\"],\n",
    "        \"dbp\": [\"[DBP]\"],\n",
    "        \"pain\": [\"[PAIN]\"],\n",
    "        \"chiefcomplaint\": [\"[CHIEF COMPLAINT]\"],\n",
    "        \"numbered_diagnoses\": [\"[DIAG]\"],\n",
    "        \"anchor_age\": [\"[AGE]\"],\n",
    "        \"GT_FLAG\": [\"[GT_FLAG]\"]\n",
    "    })\n",
    "\n",
    "\n",
    "    tmp_dem_dict = {\"gender\": [\"[GENDER]\"], \"race\": [\"[RACE]\"]}\n",
    "\n",
    "    # Use the same function with the temporary sample row\n",
    "    sample_prompts = generate_prompts_from_row(tmp_sample_df.to_dicts()[0], tmp_dem_dict)\n",
    "\n",
    "    # Extract the base prompt (first tuple) and the demographic prompt (second tuple)\n",
    "    sample_base_prompt = sample_prompts[0][6]\n",
    "    sample_demographic_prompt = sample_prompts[1][6]\n",
    "\n",
    "    # Build the sample prompt string\n",
    "    sample_prompt_string = (\n",
    "        f\"Here are the sample prompts:\\n\"\n",
    "        f\"BASE PROMPT:\\n\\n{sample_base_prompt}\\n\\n\\n\" + \"=\"*100 + \"\\n\\n\"\n",
    "        f\"DEMOGRAPHIC PROMPT:\\n\\n{sample_demographic_prompt}\"\n",
    "    )\n",
    "\n",
    "    # Save the sample prompt string to a text file\n",
    "    with open(prompt_template_txt_path, \"w\") as file:\n",
    "        file.write(sample_prompt_string)\n",
    "    \n",
    "    print(f\"Sample prompt template saved as: {prompt_template_txt_path}\")\n",
    "\n",
    "    return final_df, sample_prompt_string\n",
    "\n",
    "def run_sanity_check(df: pl.DataFrame, df_name: str, expected_count: int):\n",
    "    \"\"\"Runs the sanity check to verify prompt count per stay_id.\"\"\"\n",
    "    print(f\"\\n--- Sanity Check for {df_name} ---\")\n",
    "    if df.height == 0:\n",
    "        print(f\"WARNING: {df_name} is empty. Skipping sanity check.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Verifying that each stay_id in {df_name} has exactly {expected_count} prompts...\")\n",
    "\n",
    "    # Group by stay_id and count the number of rows (prompts) for each\n",
    "    prompt_counts_per_id = df.group_by(\"stay_id\").len()\n",
    "\n",
    "    # Filter to find any stay_ids that do NOT have the expected count\n",
    "    mismatched_ids = prompt_counts_per_id.filter(pl.col(\"len\") != expected_count)\n",
    "\n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if mismatched_ids.height == 0:\n",
    "        print(f\"SUCCESS: All {prompt_counts_per_id.height} unique stay_ids in {df_name} have exactly {expected_count} prompts.\")\n",
    "    else:\n",
    "        print(f\"ERROR: Found {mismatched_ids.height} stay_ids in {df_name} with an incorrect number of prompts!\")\n",
    "        print(\"stay_ids and their counts that deviate:\")\n",
    "        print(mismatched_ids) # Print only head to avoid flooding output\n",
    "        raise ValueError(f\"Sanity check failed for {df_name}: Incorrect number of prompts found for some stay_ids.\")\n",
    "    print(\"--- Sanity Check Ends ---\")\n",
    "\n",
    "\n",
    "final_df, sample_prompt_string = process_and_make_prompts(raw_data_csv_path = RAW_DATA_CSV_PATH, \n",
    "                             demographic_dict = DEMOGRAPHIC_DICT_NEW,\n",
    "                             prompt_template_txt_path = PROMPT_TEMPLATE_TXT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfa5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering DataFrame to create splits...\n",
      "Resulting DataFrame shapes: Train=(70720, 8), Validation=(4420, 8), Test=(13260, 8)\n",
      "\n",
      "--- Sanity Check for Train Set ---\n",
      "Verifying that each stay_id in Train Set has exactly 13 prompts...\n",
      "SUCCESS: All 5440 unique stay_ids in Train Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "--- Sanity Check for Validation Set ---\n",
      "Verifying that each stay_id in Validation Set has exactly 13 prompts...\n",
      "SUCCESS: All 340 unique stay_ids in Validation Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "--- Sanity Check for Test Set ---\n",
      "Verifying that each stay_id in Test Set has exactly 13 prompts...\n",
      "SUCCESS: All 1020 unique stay_ids in Test Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "Saving split datasets...\n",
      "Train dataset saved to: ALL_DATASETS/final_train_dataset.csv\n",
      "Validation dataset saved to: ALL_DATASETS/final_validation_dataset.csv\n",
      "Test dataset saved to: ALL_DATASETS/final_test_dataset.csv\n",
      "\n",
      "--- Data Processing and Splitting Complete ---\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Filter the main sampled_df to create the final datasets\n",
    "    print(\"Filtering DataFrame to create splits...\")\n",
    "    train_df = final_df.filter(pl.col(\"stay_id\").is_in(train_ids))\n",
    "    val_df = final_df.filter(pl.col(\"stay_id\").is_in(val_ids))\n",
    "    test_df = final_df.filter(pl.col(\"stay_id\").is_in(test_ids))\n",
    "\n",
    "    print(f\"Resulting DataFrame shapes: Train={train_df.shape}, Validation={val_df.shape}, Test={test_df.shape}\")\n",
    "\n",
    "    # --- Run Sanity Checks on Each Split ---\n",
    "    run_sanity_check(train_df, \"Train Set\", EXPECTED_PROMPT_COUNT)\n",
    "    run_sanity_check(val_df, \"Validation Set\", EXPECTED_PROMPT_COUNT)\n",
    "    run_sanity_check(test_df, \"Test Set\", EXPECTED_PROMPT_COUNT)\n",
    "\n",
    "    # --- Save the Split Datasets ---\n",
    "    print(\"\\nSaving split datasets...\")\n",
    "    train_df.write_csv(OUTPUT_TRAIN_CSV_PATH)\n",
    "    print(f\"Train dataset saved to: {OUTPUT_TRAIN_CSV_PATH}\") \n",
    "    val_df.write_csv(OUTPUT_VAL_CSV_PATH)\n",
    "    print(f\"Validation dataset saved to: {OUTPUT_VAL_CSV_PATH}\") \n",
    "    test_df.write_csv(OUTPUT_TEST_CSV_PATH)\n",
    "    print(f\"Test dataset saved to: {OUTPUT_TEST_CSV_PATH}\")\n",
    "\n",
    "    print(\"\\n--- Data Processing and Splitting Complete ---\")\n",
    "\n",
    "    # --- Splitiing dataset into train, val, test Code Ends Here\n",
    "    print(\"=\"*100)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal_graph2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
