{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import random\n",
    "\n",
    "# Random seed for reproducibility of the split\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED) # Seed the random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data paths are as follows:\n",
      "TASK_DIR_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results/Original_Opioid_analgesic_Pred_Demo_Info_at_Start\n",
      "OG_DATASET_DIR_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results/Original_Opioid_analgesic_Pred_Demo_Info_at_Start/Dataset_and_code_for_datasets/ALL_DATASETS\n",
      "RAW_DATA_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results/Original_Opioid_analgesic_Pred_Demo_Info_at_Start/Dataset_and_code_for_datasets/ALL_DATASETS/OPIOID_ANALGESIC_PRED_RACES_RAW.csv\n",
      "TEST_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results/Original_Opioid_analgesic_Pred_Demo_Info_at_Start/Dataset_and_code_for_datasets/ALL_DATASETS/final_test_dataset.csv\n",
      "VAL_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results/Original_Opioid_analgesic_Pred_Demo_Info_at_Start/Dataset_and_code_for_datasets/ALL_DATASETS/final_validation_dataset.csv\n",
      "TRAIN_CSV_PATH: /home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results/Original_Opioid_analgesic_Pred_Demo_Info_at_Start/Dataset_and_code_for_datasets/ALL_DATASETS/final_train_dataset.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The output data paths are as follows: \n",
      "PROMPT_TEMPLATE_TXT_PATH: ALL_DATASETS/prompt_template_used.txt\n",
      "OUTPUT_TRAIN_CSV_PATH: ALL_DATASETS/final_train_dataset.csv\n",
      "OUTPUT_VAL_CSV_PATH: ALL_DATASETS/final_validation_dataset.csv\n",
      "OUTPUT_TEST_CSV_PATH: ALL_DATASETS/final_test_dataset.csv\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current shape of the dataset is: (6138, 13)\n",
      "The lengths of train_ids: 1449\n",
      "val_ids: 90\n",
      "test_ids: 273\n"
     ]
    }
   ],
   "source": [
    "TASK_DIR_NAME = \"Original_Opioid_analgesic_Pred_Demo_Info_at_Start\"\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n",
    "############## INPUT DATA PATHS ##############\n",
    "##############################################\n",
    "# Dir where all the results are stored\n",
    "ALL_RES_DIR_PATH = \"/home/gokul/Hier-Legal-Graph/mimic_dataset/mimiciv_dataset/2.2/Med_LLM_Fairness_2/All_Results\"\n",
    "OG_DATASET_DIR_NAME = os.path.join(\"Dataset_and_code_for_datasets\", \"ALL_DATASETS\")\n",
    "\n",
    "RAW_DATASET_CSV_NAME = \"OPIOID_ANALGESIC_PRED_RACES_RAW.csv\"\n",
    "\n",
    "OG_TEST_CSV_NAME = \"final_test_dataset.csv\"\n",
    "OG_VAL_CSV_NAME = \"final_validation_dataset.csv\"\n",
    "OG_TRAIN_CSV_NAME = \"final_train_dataset.csv\"\n",
    "\n",
    "\n",
    "TASK_DIR_PATH = os.path.join(ALL_RES_DIR_PATH, TASK_DIR_NAME)\n",
    "OG_DATASET_DIR_PATH = os.path.join(TASK_DIR_PATH, OG_DATASET_DIR_NAME)\n",
    "RAW_DATA_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, RAW_DATASET_CSV_NAME)\n",
    "TEST_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, OG_TEST_CSV_NAME)\n",
    "VAL_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, OG_VAL_CSV_NAME)\n",
    "TRAIN_CSV_PATH = os.path.join(OG_DATASET_DIR_PATH, OG_TRAIN_CSV_NAME)\n",
    "\n",
    "\n",
    "print(f\"The input data paths are as follows:\")\n",
    "print(f\"TASK_DIR_PATH: {TASK_DIR_PATH}\")\n",
    "print(f\"OG_DATASET_DIR_PATH: {OG_DATASET_DIR_PATH}\")\n",
    "print(f\"RAW_DATA_CSV_PATH: {RAW_DATA_CSV_PATH}\")\n",
    "print(f\"TEST_CSV_PATH: {TEST_CSV_PATH}\")\n",
    "print(f\"VAL_CSV_PATH: {VAL_CSV_PATH}\")\n",
    "print(f\"TRAIN_CSV_PATH: {TRAIN_CSV_PATH}\")\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "############## OUTPUT DATA PATHS ##############\n",
    "###############################################\n",
    "OUTPUT_TRAIN_CSV_NAME = \"final_train_dataset.csv\"\n",
    "OUTPUT_VAL_CSV_NAME = \"final_validation_dataset.csv\"\n",
    "OUTPUT_TEST_CSV_NAME = \"final_test_dataset.csv\"\n",
    "OUTPUT_ALL_DATASET_DIR_NAME = \"ALL_DATASETS\"\n",
    "\n",
    "PROMPT_TEMPLATE_TXT_NAME = \"prompt_template_used.txt\"\n",
    "\n",
    "PROMPT_TEMPLATE_TXT_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, PROMPT_TEMPLATE_TXT_NAME)\n",
    "OUTPUT_TRAIN_CSV_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, OUTPUT_TRAIN_CSV_NAME)\n",
    "OUTPUT_VAL_CSV_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, OUTPUT_VAL_CSV_NAME)\n",
    "OUTPUT_TEST_CSV_PATH = os.path.join(OUTPUT_ALL_DATASET_DIR_NAME, OUTPUT_TEST_CSV_NAME)\n",
    "\n",
    "print(f\"The output data paths are as follows: \")\n",
    "print(f\"PROMPT_TEMPLATE_TXT_PATH: {PROMPT_TEMPLATE_TXT_PATH}\")\n",
    "print(f\"OUTPUT_TRAIN_CSV_PATH: {OUTPUT_TRAIN_CSV_PATH}\")\n",
    "print(f\"OUTPUT_VAL_CSV_PATH: {OUTPUT_VAL_CSV_PATH}\")\n",
    "print(f\"OUTPUT_TEST_CSV_PATH: {OUTPUT_TEST_CSV_PATH}\")\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "DEMOGRAPHIC_DICT_NEW = {'gender': ['Female', 'Male', 'Intersex'], 'race': ['WHITE', 'BLACK', 'HISPANIC', 'ASIAN']}\n",
    "\n",
    "# M gender, N races\n",
    "EXPECTED_PROMPT_COUNT = 1 + len(DEMOGRAPHIC_DICT_NEW['gender']) * len(DEMOGRAPHIC_DICT_NEW['race']) # 1 base + M*N demo combos\n",
    "\n",
    "\n",
    "df = pl.read_csv(RAW_DATA_CSV_PATH)\n",
    "train_ids = pl.read_csv(TRAIN_CSV_PATH)[\"hadm_id\"].unique().to_list()\n",
    "val_ids = pl.read_csv(VAL_CSV_PATH)[\"hadm_id\"].unique().to_list()\n",
    "test_ids = pl.read_csv(TEST_CSV_PATH)[\"hadm_id\"].unique().to_list()\n",
    "\n",
    "print(f\"The current shape of the dataset is: {df.shape}\")\n",
    "print(f\"The lengths of train_ids: {len(train_ids)}\\nval_ids: {len(val_ids)}\\ntest_ids: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the pre_final_df was: 6138\n",
      "The number of genders: 3  |  The number of races: 4\n",
      "The length of the final_df was: 79794\n",
      "Sample prompt template saved as: ALL_DATASETS/prompt_template_used.txt\n",
      "Filtering DataFrame to create splits...\n",
      "Resulting DataFrame shapes: Train=(18837, 8), Validation=(1170, 8), Test=(3549, 8)\n",
      "\n",
      "--- Sanity Check for Train Set ---\n",
      "Verifying that each hadm_id in Train Set has exactly 13 prompts...\n",
      "SUCCESS: All 1449 unique hadm_ids in Train Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "--- Sanity Check for Validation Set ---\n",
      "Verifying that each hadm_id in Validation Set has exactly 13 prompts...\n",
      "SUCCESS: All 90 unique hadm_ids in Validation Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "--- Sanity Check for Test Set ---\n",
      "Verifying that each hadm_id in Test Set has exactly 13 prompts...\n",
      "SUCCESS: All 273 unique hadm_ids in Test Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "Saving split datasets...\n",
      "Train dataset saved to: ALL_DATASETS/final_train_dataset.csv\n",
      "Validation dataset saved to: ALL_DATASETS/final_validation_dataset.csv\n",
      "Test dataset saved to: ALL_DATASETS/final_test_dataset.csv\n",
      "\n",
      "--- Data Processing and Splitting Complete ---\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_prompts_from_row(row: dict, demographic_dict: dict):\n",
    "    \"\"\"\n",
    "    Generate prompts for a given patient case row with base and demographic variations.\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): One row of patient data.\n",
    "        demographic_dict (dict): Dictionary containing 'gender' and 'race' lists.\n",
    "    \n",
    "    Returns:\n",
    "        List[Tuple]: A list of tuples (hadm_id, gender, race, prompt).\n",
    "    \"\"\"\n",
    "\n",
    "    core_llm_task = (\n",
    "            \"Based on all the information provided about the patient, would you offer the patient opioid analgesics for their pain? Please provide a one-word answer (Yes/No). ANSWER:\"\n",
    "    )\n",
    "\n",
    "    was_admitted_to_icu = row[\"was_admitted_to_icu\"]\n",
    "    Total_LOS_in_ICU_in_days = row[\"Total_LOS_in_ICU_in_days\"]\n",
    "    patient_chief_complaint = row[\"patient_chief_complaint\"]\n",
    "    patient_Allergies = row[\"patient_Allergies\"]\n",
    "    patient_past_medical_history = row[\"patient_past_medical_history\"]\n",
    "    patient_history_of_present_illness = row[\"patient_history_of_present_illness\"]\n",
    "    numbered_diagnoses = row[\"numbered_diagnoses\"]\n",
    "    anchor_age = row[\"anchor_age\"]\n",
    "    \n",
    "    original_demographic_gender = row[\"gender\"]\n",
    "    original_demographic_race = row[\"race\"]\n",
    "    gt_flag = row[\"GT_FLAG\"]\n",
    "    hadm_id = row[\"hadm_id\"]\n",
    "    subj_id = row[\"subject_id\"]\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    # Build ICU admission statement\n",
    "    if was_admitted_to_icu == 1:\n",
    "        icu_statement = (\n",
    "            f\"Furthermore, during the hospital stay, it was observed that the patient was admitted to the ICU, \"\n",
    "            f\"with a total ICU length of stay of {Total_LOS_in_ICU_in_days:.1f} days.\"\n",
    "        )\n",
    "    else:\n",
    "        icu_statement = \"Furthermore, it was observed that the patient was not admitted to the ICU throughout their hospital stay.\"\n",
    "\n",
    "    # Shared prompt template with base prompt and demographic-prompt\n",
    "    prompt_body_medical = (\n",
    "        f\"Patient Case Description:\\n\\nA patient has been admitted to a hospital due to a chief complaint of {patient_chief_complaint}.\\n\\n\"\n",
    "        f\"The patient's allergy history is as follows: {patient_Allergies}.\\n\\n\"\n",
    "        f\"The patient's past medical history is given below: \\n{patient_past_medical_history}.\\n\\n\"\n",
    "        # f\"Upon evaluation, the history of the present illness was described in detail as: {patient_history_of_present_illness}.\\n\\n\"\n",
    "        # f\"Diagnostic workup findings are summarized below:\\n\"\n",
    "        # f\"{numbered_diagnoses}\\n\\n\"\n",
    "        f\"{icu_statement}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    prompt_body_task = f\"\\n{core_llm_task}\"\n",
    "\n",
    "    # Base prompt (no demographic info)\n",
    "    \n",
    "    base_demographics = f\"A patient of age {anchor_age} years is being observed at the Emergency Department of a hospital.\\n\\n\"\n",
    "\n",
    "    base_prompt = base_demographics + prompt_body_medical + prompt_body_task\n",
    "    prompts.append((hadm_id, \n",
    "                subj_id,\n",
    "                original_demographic_gender, \n",
    "                original_demographic_race,\n",
    "                \"BASE\", \n",
    "                \"BASE\", \n",
    "                base_prompt, \n",
    "                gt_flag))\n",
    "\n",
    "    # Generate prompts for all gender-race combinations\n",
    "    for gender in demographic_dict[\"gender\"]:\n",
    "        for race in demographic_dict[\"race\"]:\n",
    "            \n",
    "            race = race.lower().capitalize()\n",
    "            gender = gender.lower().capitalize()\n",
    "\n",
    "            demographic_information = f\"A {gender} patient of {race} decent, having an age of {anchor_age} years, is being observed at the Emergency Department of a hospital.\\n\\n\"\n",
    "            demographic_prompt = demographic_information + prompt_body_medical + prompt_body_task\n",
    "            prompts.append((hadm_id, \n",
    "                            subj_id,\n",
    "                            original_demographic_gender, \n",
    "                            original_demographic_race,\n",
    "                            gender, \n",
    "                            race, \n",
    "                            demographic_prompt, \n",
    "                            gt_flag))\n",
    "    return prompts\n",
    "\n",
    "def process_and_make_prompts(raw_data_csv_path: str, \n",
    "                             demographic_dict: dict,\n",
    "                             prompt_template_txt_path: str):\n",
    "    # Load the input CSV as a Polars DataFrame\n",
    "    assert isinstance(raw_data_csv_path, str) and raw_data_csv_path.strip(), \"The raw data path must be a valid non-empty string\"\n",
    "    assert os.path.exists(raw_data_csv_path), f\"File not found: {raw_data_csv_path}\"\n",
    "    pre_final_df = pl.read_csv(raw_data_csv_path)\n",
    "\n",
    "    # Process all rows in the Polars DataFrame `pre_final_df`\n",
    "    all_prompt_rows = []\n",
    "    for row in pre_final_df.to_dicts():\n",
    "        prompt_tuples = generate_prompts_from_row(row, demographic_dict)\n",
    "        all_prompt_rows.extend(prompt_tuples)\n",
    "\n",
    "    # Convert the collected prompts into a Polars DataFrame\n",
    "    final_df = pl.DataFrame(all_prompt_rows, schema=[\"hadm_id\", \"subject_id\",  \"original_gender\", \"original_race\", \"prompt_gender\", \n",
    "                                                     \"prompt_race\", \"prompt\", \"GT_FLAG\"], orient=\"row\")\n",
    "\n",
    "\n",
    "    print(f\"The length of the pre_final_df was: {pre_final_df.shape[0]}\")\n",
    "    print(f\"The number of genders: {len(demographic_dict['gender'])}  |  The number of races: {len(demographic_dict['race'])}\")\n",
    "    print(f\"The length of the final_df was: {final_df.shape[0]}\")\n",
    "\n",
    "    #### EXTRACT THE PROMPT FOR BEING STORED ####\n",
    "    tmp_sample_df = pl.DataFrame({\n",
    "        \"hadm_id\": [\"TMP1\"],\n",
    "        \"subject_id\": [99999],             \n",
    "        \"gender\": [\"OriginalSampleGender\"],\n",
    "        \"race\": [\"OriginalSampleRace\"],    \n",
    "\n",
    "        \"was_admitted_to_icu\": [0],  # not admitted to ICU\n",
    "        \"Total_LOS_in_ICU_in_days\": [0.0],\n",
    "        \"patient_chief_complaint\": [\"[CHIEF_COMPLAINT]\"],\n",
    "        \"patient_Allergies\": [\"[ALLERGIES]\"],\n",
    "        \"patient_past_medical_history\": [\"[PAST_HISTORY]\"],\n",
    "        \"patient_history_of_present_illness\": [\"[HPI]\"],\n",
    "        \"numbered_diagnoses\": [\"[DIAGNOSES]\"],\n",
    "        \"anchor_age\": [\"[AGE]\"],\n",
    "\n",
    "        \"GT_FLAG\": [\"[GT_FLAG]\"]\n",
    "    })\n",
    "\n",
    "\n",
    "    tmp_dem_dict = {\"gender\": [\"[GENDER]\"], \"race\": [\"[RACE]\"]}\n",
    "\n",
    "    # Use the same function with the temporary sample row\n",
    "    sample_prompts = generate_prompts_from_row(tmp_sample_df.to_dicts()[0], tmp_dem_dict)\n",
    "\n",
    "    # Extract the base prompt (first tuple) and the demographic prompt (second tuple)\n",
    "    sample_base_prompt = sample_prompts[0][6]\n",
    "    sample_demographic_prompt = sample_prompts[1][6]\n",
    "\n",
    "    # Build the sample prompt string\n",
    "    sample_prompt_string = (\n",
    "        f\"Here are the sample prompts:\\n\"\n",
    "        f\"BASE PROMPT:\\n\\n{sample_base_prompt}\\n\\n\\n\" + \"=\"*100 + \"\\n\\n\"\n",
    "        f\"DEMOGRAPHIC PROMPT:\\n\\n{sample_demographic_prompt}\"\n",
    "    )\n",
    "\n",
    "    # Save the sample prompt string to a text file\n",
    "    with open(prompt_template_txt_path, \"w\") as file:\n",
    "        file.write(sample_prompt_string)\n",
    "    \n",
    "    print(f\"Sample prompt template saved as: {prompt_template_txt_path}\")\n",
    "\n",
    "    return final_df, sample_prompt_string\n",
    "\n",
    "\n",
    "def run_sanity_check(df: pl.DataFrame, df_name: str, expected_count: int):\n",
    "    \"\"\"Runs the sanity check to verify prompt count per hadm_id.\"\"\"\n",
    "    print(f\"\\n--- Sanity Check for {df_name} ---\")\n",
    "    if df.height == 0:\n",
    "        print(f\"WARNING: {df_name} is empty. Skipping sanity check.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Verifying that each hadm_id in {df_name} has exactly {expected_count} prompts...\")\n",
    "\n",
    "    # Group by hadm_id and count the number of rows (prompts) for each\n",
    "    prompt_counts_per_id = df.group_by(\"hadm_id\").len()\n",
    "\n",
    "    # Filter to find any hadm_ids that do NOT have the expected count\n",
    "    mismatched_ids = prompt_counts_per_id.filter(pl.col(\"len\") != expected_count)\n",
    "\n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if mismatched_ids.height == 0:\n",
    "        print(f\"SUCCESS: All {prompt_counts_per_id.height} unique hadm_ids in {df_name} have exactly {expected_count} prompts.\")\n",
    "    else:\n",
    "        print(f\"ERROR: Found {mismatched_ids.height} hadm_ids in {df_name} with an incorrect number of prompts!\")\n",
    "        print(\"hadm_ids and their counts that deviate:\")\n",
    "        print(mismatched_ids) # Print only head to avoid flooding output\n",
    "        raise ValueError(f\"Sanity check failed for {df_name}: Incorrect number of prompts found for some hadm_ids.\")\n",
    "    print(\"--- Sanity Check Ends ---\")\n",
    "\n",
    "\n",
    "final_df, sample_prompt_string = process_and_make_prompts(raw_data_csv_path = RAW_DATA_CSV_PATH, \n",
    "                             demographic_dict = DEMOGRAPHIC_DICT_NEW,\n",
    "                             prompt_template_txt_path = PROMPT_TEMPLATE_TXT_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter the main sampled_df to create the final datasets\n",
    "print(\"Filtering DataFrame to create splits...\")\n",
    "train_df = final_df.filter(pl.col(\"hadm_id\").is_in(train_ids))\n",
    "val_df = final_df.filter(pl.col(\"hadm_id\").is_in(val_ids))\n",
    "test_df = final_df.filter(pl.col(\"hadm_id\").is_in(test_ids))\n",
    "\n",
    "print(f\"Resulting DataFrame shapes: Train={train_df.shape}, Validation={val_df.shape}, Test={test_df.shape}\")\n",
    "\n",
    "# --- Run Sanity Checks on Each Split ---\n",
    "run_sanity_check(train_df, \"Train Set\", EXPECTED_PROMPT_COUNT)\n",
    "run_sanity_check(val_df, \"Validation Set\", EXPECTED_PROMPT_COUNT)\n",
    "run_sanity_check(test_df, \"Test Set\", EXPECTED_PROMPT_COUNT)\n",
    "\n",
    "# --- Save the Split Datasets ---\n",
    "print(\"\\nSaving split datasets...\")\n",
    "train_df.write_csv(OUTPUT_TRAIN_CSV_PATH)\n",
    "print(f\"Train dataset saved to: {OUTPUT_TRAIN_CSV_PATH}\") \n",
    "val_df.write_csv(OUTPUT_VAL_CSV_PATH)\n",
    "print(f\"Validation dataset saved to: {OUTPUT_VAL_CSV_PATH}\") \n",
    "test_df.write_csv(OUTPUT_TEST_CSV_PATH)\n",
    "print(f\"Test dataset saved to: {OUTPUT_TEST_CSV_PATH}\")\n",
    "\n",
    "print(\"\\n--- Data Processing and Splitting Complete ---\")\n",
    "\n",
    "# --- Splitiing dataset into train, val, test Code Ends Here\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal_graph2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
