{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CHANGE THIS / HAVE A LOOK AT THIS BEFORE RUNNING THE SCRIPT ##############\n",
    "\n",
    "def additional_processing_of_pre_final_df(pre_final_df: pl.DataFrame)-> pl.DataFrame:\n",
    "    \n",
    "    # To get only ICU Admissions\n",
    "    #pre_final_df_modified = pre_final_df.filter(pl.col(\"was_admitted_to_icu\") == 1)\n",
    "\n",
    "    # Do Nothing\n",
    "    pre_final_df_modified = pre_final_df\n",
    "\n",
    "    return pre_final_df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current shape of the dataset is: (6138, 13)\n"
     ]
    }
   ],
   "source": [
    "# Name of Dir that stores all the datasets\n",
    "ALL_DATASET_PATH = \"ALL_DATASETS\"\n",
    "# Name of file to load and make the prompts from\n",
    "RAW_DATA_CSV_NAME = \"OPIOID_ANALGESIC_PRED_RACES_RAW.csv\"\n",
    "# Name of file to store the main dataset with all prompts for all IDs\n",
    "FINAL_DF_CSV_NAME = \"main_data_with_all_prompts_for_all_IDs_without_sampling_GT.csv\"\n",
    "# Name of file that stores the sample prompt template used.\n",
    "PROMPT_TEMPLATE_TXT_NAME = \"prompt_template_used.txt\"\n",
    "\n",
    "# Name of file to store the GT-sampled dataset with prompts\n",
    "SAMPLED_DF_CSV_NAME = \"main_data_with_all_prompts_for_all_IDs_AFTER_sampling_GT_to_be_uniformly_distributed.csv\"\n",
    "\n",
    "DEMOGRAPHIC_DICT_NEW = {'gender': ['Female', 'Male', 'Intersex'], 'race': ['WHITE', 'BLACK', 'HISPANIC', 'ASIAN']}\n",
    "\n",
    "RAW_DATA_CSV_PATH = os.path.join(ALL_DATASET_PATH, RAW_DATA_CSV_NAME)\n",
    "FINAL_DF_CSV_PATH = os.path.join(ALL_DATASET_PATH, FINAL_DF_CSV_NAME)\n",
    "PROMPT_TEMPLATE_TXT_PATH = os.path.join(ALL_DATASET_PATH, PROMPT_TEMPLATE_TXT_NAME)\n",
    "SAMPLED_DF_CSV_PATH = os.path.join(ALL_DATASET_PATH, SAMPLED_DF_CSV_NAME)\n",
    "\n",
    "# M gender, N races\n",
    "EXPECTED_PROMPT_COUNT = 1 + len(DEMOGRAPHIC_DICT_NEW['gender']) * len(DEMOGRAPHIC_DICT_NEW['race']) # 1 base + M*N demo combos\n",
    "\n",
    "# Split percentages (ensure they sum to 1.0)\n",
    "TRAIN_SPLIT_PERC = 0.80\n",
    "VAL_SPLIT_PERC = 0.05\n",
    "TEST_SPLIT_PERC = 0.15\n",
    "assert abs(TRAIN_SPLIT_PERC + VAL_SPLIT_PERC + TEST_SPLIT_PERC - 1.0) < 1e-9, \"Split percentages must sum to 1.0\"\n",
    "\n",
    "# Output file names for the splits\n",
    "TRAIN_DF_CSV_NAME = \"final_train_dataset.csv\"\n",
    "VAL_DF_CSV_NAME = \"final_validation_dataset.csv\"\n",
    "TEST_DF_CSV_NAME = \"final_test_dataset.csv\"\n",
    "\n",
    "# Output file paths\n",
    "TRAIN_DF_CSV_PATH = os.path.join(ALL_DATASET_PATH, TRAIN_DF_CSV_NAME)\n",
    "VAL_DF_CSV_PATH = os.path.join(ALL_DATASET_PATH, VAL_DF_CSV_NAME)\n",
    "TEST_DF_CSV_PATH = os.path.join(ALL_DATASET_PATH, TEST_DF_CSV_NAME)\n",
    "\n",
    "# Random seed for reproducibility of the split\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED) # Seed the random module\n",
    "\n",
    "df = pl.read_csv(RAW_DATA_CSV_PATH)\n",
    "print(f\"The current shape of the dataset is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the pre_final_df was: 6138\n",
      "The number of genders: 3  |  The number of races: 4\n",
      "The length of the final_df was: 79794\n",
      "Sample prompt template saved as: ALL_DATASETS/prompt_template_used.txt\n",
      "DataFrame with all prompts for all IDs without sampling GT saved as: ALL_DATASETS/main_data_with_all_prompts_for_all_IDs_without_sampling_GT.csv\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- Stratified Sampling based on GT_FLAG (Sampling by hadm_id) ---\n",
      "Found 6138 unique hadm_ids by filtering BASE prompts.\n",
      "Minimum number of hadm_ids per GT_FLAG group: 906\n",
      "Total number of hadm_ids sampled: 1812 (906 per GT group)\n",
      "Shape of the original final DataFrame: (79794, 8)\n",
      "Shape of the sampled DataFrame (containing all prompts for sampled IDs): (23556, 8)\n",
      "Distribution of unique hadm_ids per GT_FLAG in the sampled DataFrame:\n",
      "shape: (2, 2)\n",
      "┌─────────┬─────┐\n",
      "│ GT_FLAG ┆ len │\n",
      "│ ---     ┆ --- │\n",
      "│ str     ┆ u32 │\n",
      "╞═════════╪═════╡\n",
      "│ YES     ┆ 906 │\n",
      "│ NO      ┆ 906 │\n",
      "└─────────┴─────┘\n",
      "\n",
      "--- Sanity Check for Sampled_data_with_uniform_ground_truth_distribution ---\n",
      "Verifying that each hadm_id in Sampled_data_with_uniform_ground_truth_distribution has exactly 13 prompts...\n",
      "SUCCESS: All 1812 unique hadm_ids in Sampled_data_with_uniform_ground_truth_distribution have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "Sampled DataFrame (by hadm_id) saved as: ALL_DATASETS/main_data_with_all_prompts_for_all_IDs_AFTER_sampling_GT_to_be_uniformly_distributed.csv\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- Splitting GT-Sampled Data into Train/Val/Test Sets ---\n",
      "Total unique hadm_ids to split: 1812\n",
      "Shuffled unique hadm_ids using seed 42.\n",
      "Split sizes (by hadm_id): Train=1449, Validation=90, Test=273\n",
      "Filtering DataFrame to create splits...\n",
      "Resulting DataFrame shapes: Train=(18837, 8), Validation=(1170, 8), Test=(3549, 8)\n",
      "\n",
      "--- Sanity Check for Train Set ---\n",
      "Verifying that each hadm_id in Train Set has exactly 13 prompts...\n",
      "SUCCESS: All 1449 unique hadm_ids in Train Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "--- Sanity Check for Validation Set ---\n",
      "Verifying that each hadm_id in Validation Set has exactly 13 prompts...\n",
      "SUCCESS: All 90 unique hadm_ids in Validation Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "--- Sanity Check for Test Set ---\n",
      "Verifying that each hadm_id in Test Set has exactly 13 prompts...\n",
      "SUCCESS: All 273 unique hadm_ids in Test Set have exactly 13 prompts.\n",
      "--- Sanity Check Ends ---\n",
      "\n",
      "Saving split datasets...\n",
      "Train dataset saved to: ALL_DATASETS/final_train_dataset.csv\n",
      "Validation dataset saved to: ALL_DATASETS/final_validation_dataset.csv\n",
      "Test dataset saved to: ALL_DATASETS/final_test_dataset.csv\n",
      "\n",
      "--- Data Processing and Splitting Complete ---\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_prompts_from_row(row: dict, demographic_dict: dict):\n",
    "    \"\"\"\n",
    "    Generate prompts for a given patient case row with base and demographic variations.\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): One row of patient data.\n",
    "        demographic_dict (dict): Dictionary containing 'gender' and 'race' lists.\n",
    "    \n",
    "    Returns:\n",
    "        List[Tuple]: A list of tuples (hadm_id, gender, race, prompt).\n",
    "    \"\"\"\n",
    "\n",
    "    core_llm_task = (\n",
    "            \"Based on all the information provided about the patient, would you offer the patient opioid analgesics for their pain? Please provide a one-word answer (Yes/No). ANSWER:\"\n",
    "    )\n",
    "\n",
    "    was_admitted_to_icu = row[\"was_admitted_to_icu\"]\n",
    "    Total_LOS_in_ICU_in_days = row[\"Total_LOS_in_ICU_in_days\"]\n",
    "    patient_chief_complaint = row[\"patient_chief_complaint\"]\n",
    "    patient_Allergies = row[\"patient_Allergies\"]\n",
    "    patient_past_medical_history = row[\"patient_past_medical_history\"]\n",
    "    patient_history_of_present_illness = row[\"patient_history_of_present_illness\"]\n",
    "    numbered_diagnoses = row[\"numbered_diagnoses\"]\n",
    "    anchor_age = row[\"anchor_age\"]\n",
    "    \n",
    "    original_demographic_gender = row[\"gender\"]\n",
    "    original_demographic_race = row[\"race\"]\n",
    "    gt_flag = row[\"GT_FLAG\"]\n",
    "    hadm_id = row[\"hadm_id\"]\n",
    "    subj_id = row[\"subject_id\"]\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    # Build ICU admission statement\n",
    "    if was_admitted_to_icu == 1:\n",
    "        icu_statement = (\n",
    "            f\"Furthermore, during the hospital stay, it was observed that the patient was admitted to the ICU, \"\n",
    "            f\"with a total ICU length of stay of {Total_LOS_in_ICU_in_days:.1f} days.\"\n",
    "        )\n",
    "    else:\n",
    "        icu_statement = \"Furthermore, it was observed that the patient was not admitted to the ICU throughout their hospital stay.\"\n",
    "\n",
    "    # Shared prompt template with base prompt and demographic-prompt\n",
    "    prompt_body_medical = (\n",
    "        f\"Patient Case Description:\\n\\nA patient has been admitted to a hospital due to a chief complaint of {patient_chief_complaint}.\\n\\n\"\n",
    "        f\"The patient's allergy history is as follows: {patient_Allergies}.\\n\\n\"\n",
    "        f\"The patient's past medical history is given below: \\n{patient_past_medical_history}.\\n\\n\"\n",
    "        f\"Upon evaluation, the history of the present illness was described in detail as: {patient_history_of_present_illness}.\\n\\n\"\n",
    "        f\"Diagnostic workup findings are summarized below:\\n\"\n",
    "        f\"{numbered_diagnoses}\\n\\n\"\n",
    "        f\"{icu_statement}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    prompt_body_task = f\"\\n{core_llm_task}\"\n",
    "\n",
    "    # Base prompt (no demographic info)\n",
    "    \n",
    "    base_demographics = f\"A patient of age {anchor_age} years is being observed at the Emergency Department of a hospital.\\n\\n\"\n",
    "\n",
    "    base_prompt = base_demographics + prompt_body_medical + prompt_body_task\n",
    "    prompts.append((hadm_id, \n",
    "                subj_id,\n",
    "                original_demographic_gender, \n",
    "                original_demographic_race,\n",
    "                \"BASE\", \n",
    "                \"BASE\", \n",
    "                base_prompt, \n",
    "                gt_flag))\n",
    "\n",
    "    # Generate prompts for all gender-race combinations\n",
    "    for gender in demographic_dict[\"gender\"]:\n",
    "        for race in demographic_dict[\"race\"]:\n",
    "            \n",
    "            race = race.lower().capitalize()\n",
    "            gender = gender.lower().capitalize()\n",
    "\n",
    "            demographic_information = f\"A {gender} patient of {race} decent, having an age of {anchor_age} years, is being observed at the Emergency Department of a hospital.\\n\\n\"\n",
    "            demographic_prompt = demographic_information + prompt_body_medical + prompt_body_task\n",
    "            prompts.append((hadm_id, \n",
    "                            subj_id,\n",
    "                            original_demographic_gender, \n",
    "                            original_demographic_race,\n",
    "                            gender, \n",
    "                            race, \n",
    "                            demographic_prompt, \n",
    "                            gt_flag))\n",
    "    return prompts\n",
    "\n",
    "def process_and_make_prompts(raw_data_csv_path: str, \n",
    "                             demographic_dict: dict,\n",
    "                             final_df_csv_path: str,\n",
    "                             prompt_template_txt_path: str):\n",
    "    # Load the input CSV as a Polars DataFrame\n",
    "    assert isinstance(raw_data_csv_path, str) and raw_data_csv_path.strip(), \"The raw data path must be a valid non-empty string\"\n",
    "    assert os.path.exists(raw_data_csv_path), f\"File not found: {raw_data_csv_path}\"\n",
    "    pre_final_df = pl.read_csv(raw_data_csv_path)\n",
    "\n",
    "    pre_final_df = additional_processing_of_pre_final_df(pre_final_df=pre_final_df)\n",
    "\n",
    "    # Process all rows in the Polars DataFrame `pre_final_df`\n",
    "    all_prompt_rows = []\n",
    "    for row in pre_final_df.to_dicts():\n",
    "        prompt_tuples = generate_prompts_from_row(row, demographic_dict)\n",
    "        all_prompt_rows.extend(prompt_tuples)\n",
    "\n",
    "    # Convert the collected prompts into a Polars DataFrame\n",
    "    final_df = pl.DataFrame(all_prompt_rows, schema=[\"hadm_id\", \"subject_id\",  \"original_gender\", \"original_race\", \"prompt_gender\", \n",
    "                                                     \"prompt_race\", \"prompt\", \"GT_FLAG\"], orient=\"row\")\n",
    "\n",
    "\n",
    "    print(f\"The length of the pre_final_df was: {pre_final_df.shape[0]}\")\n",
    "    print(f\"The number of genders: {len(demographic_dict['gender'])}  |  The number of races: {len(demographic_dict['race'])}\")\n",
    "    print(f\"The length of the final_df was: {final_df.shape[0]}\")\n",
    "\n",
    "\n",
    "    #### EXTRACT THE PROMPT FOR BEING STORED ####\n",
    "    tmp_sample_df = pl.DataFrame({\n",
    "        \"hadm_id\": [\"TMP1\"],\n",
    "        \"subject_id\": [99999],             \n",
    "        \"gender\": [\"OriginalSampleGender\"],\n",
    "        \"race\": [\"OriginalSampleRace\"],    \n",
    "\n",
    "        \"was_admitted_to_icu\": [0],  # not admitted to ICU\n",
    "        \"Total_LOS_in_ICU_in_days\": [0.0],\n",
    "        \"patient_chief_complaint\": [\"[CHIEF_COMPLAINT]\"],\n",
    "        \"patient_Allergies\": [\"[ALLERGIES]\"],\n",
    "        \"patient_past_medical_history\": [\"[PAST_HISTORY]\"],\n",
    "        \"patient_history_of_present_illness\": [\"[HPI]\"],\n",
    "        \"numbered_diagnoses\": [\"[DIAGNOSES]\"],\n",
    "        \"anchor_age\": [\"[AGE]\"],\n",
    "\n",
    "        \"GT_FLAG\": [\"[GT_FLAG]\"]\n",
    "    })\n",
    "\n",
    "\n",
    "    tmp_dem_dict = {\"gender\": [\"[GENDER]\"], \"race\": [\"[RACE]\"]}\n",
    "\n",
    "    # Use the same function with the temporary sample row\n",
    "    sample_prompts = generate_prompts_from_row(tmp_sample_df.to_dicts()[0], tmp_dem_dict)\n",
    "\n",
    "    # Extract the base prompt (first tuple) and the demographic prompt (second tuple)\n",
    "    sample_base_prompt = sample_prompts[0][6]\n",
    "    sample_demographic_prompt = sample_prompts[1][6]\n",
    "\n",
    "    # Build the sample prompt string\n",
    "    sample_prompt_string = (\n",
    "        f\"Here are the sample prompts:\\n\"\n",
    "        f\"BASE PROMPT:\\n\\n{sample_base_prompt}\\n\\n\\n\" + \"=\"*100 + \"\\n\\n\"\n",
    "        f\"DEMOGRAPHIC PROMPT:\\n\\n{sample_demographic_prompt}\"\n",
    "    )\n",
    "\n",
    "    # Save the sample prompt string to a text file\n",
    "    with open(prompt_template_txt_path, \"w\") as file:\n",
    "        file.write(sample_prompt_string)\n",
    "    \n",
    "    print(f\"Sample prompt template saved as: {prompt_template_txt_path}\")\n",
    "\n",
    "    return final_df, sample_prompt_string\n",
    "\n",
    "\n",
    "def run_sanity_check(df: pl.DataFrame, df_name: str, expected_count: int):\n",
    "    \"\"\"Runs the sanity check to verify prompt count per hadm_id.\"\"\"\n",
    "    print(f\"\\n--- Sanity Check for {df_name} ---\")\n",
    "    if df.height == 0:\n",
    "        print(f\"WARNING: {df_name} is empty. Skipping sanity check.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Verifying that each hadm_id in {df_name} has exactly {expected_count} prompts...\")\n",
    "\n",
    "    # Group by hadm_id and count the number of rows (prompts) for each\n",
    "    prompt_counts_per_id = df.group_by(\"hadm_id\").len()\n",
    "\n",
    "    # Filter to find any hadm_ids that do NOT have the expected count\n",
    "    mismatched_ids = prompt_counts_per_id.filter(pl.col(\"len\") != expected_count)\n",
    "\n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if mismatched_ids.height == 0:\n",
    "        print(f\"SUCCESS: All {prompt_counts_per_id.height} unique hadm_ids in {df_name} have exactly {expected_count} prompts.\")\n",
    "    else:\n",
    "        print(f\"ERROR: Found {mismatched_ids.height} hadm_ids in {df_name} with an incorrect number of prompts!\")\n",
    "        print(\"hadm_ids and their counts that deviate:\")\n",
    "        print(mismatched_ids) # Print only head to avoid flooding output\n",
    "        raise ValueError(f\"Sanity check failed for {df_name}: Incorrect number of prompts found for some hadm_ids.\")\n",
    "    print(\"--- Sanity Check Ends ---\")\n",
    "\n",
    "\n",
    "final_df, _ = process_and_make_prompts(raw_data_csv_path = RAW_DATA_CSV_PATH, \n",
    "                             demographic_dict = DEMOGRAPHIC_DICT_NEW,\n",
    "                             final_df_csv_path = FINAL_DF_CSV_PATH,\n",
    "                             prompt_template_txt_path = PROMPT_TEMPLATE_TXT_PATH)\n",
    "\n",
    "# Save the final_df as a CSV file\n",
    "final_df.write_csv(FINAL_DF_CSV_PATH)\n",
    "print(f\"DataFrame with all prompts for all IDs without sampling GT saved as: {FINAL_DF_CSV_PATH}\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# --- Stratified Sampling based on GT_FLAG (Sampling hadm_ids) ---\n",
    "\n",
    "print(\"\\n\\n\\n--- Stratified Sampling based on GT_FLAG (Sampling by hadm_id) ---\")\n",
    "\n",
    "# 1. Get unique hadm_ids and their corresponding GT_FLAG by using the 'BASE' prompt row\n",
    "#    Filter for BASE prompts, then select the necessary columns.\n",
    "#    Each hadm_id has exactly one BASE prompt row.\n",
    "unique_stays_df = final_df.filter(\n",
    "    pl.col(\"prompt_gender\") == \"BASE\" # Can use either prompt_gender or prompt_race\n",
    ").select(\n",
    "    [\"hadm_id\", \"GT_FLAG\"]\n",
    ")\n",
    "print(f\"Found {unique_stays_df.shape[0]} unique hadm_ids by filtering BASE prompts.\")\n",
    "\n",
    "# 2. Calculate the minimum number of hadm_ids for any GT_FLAG group\n",
    "min_hadm_id_group_size = unique_stays_df.group_by(\"GT_FLAG\").len().min().get_column(\"len\")[0]\n",
    "print(f\"Minimum number of hadm_ids per GT_FLAG group: {min_hadm_id_group_size}\")\n",
    "\n",
    "# 3. Perform stratified sampling on the unique hadm_ids\n",
    "#    Sample 'min_hadm_id_group_size' hadm_ids from each GT_FLAG group.\n",
    "sampled_unique_stays = unique_stays_df.group_by(\"GT_FLAG\", maintain_order=False).map_groups(\n",
    "    lambda group: group.sample(n=min_hadm_id_group_size, with_replacement=False, shuffle=True)\n",
    ")\n",
    "\n",
    "# 4. Extract the list of hadm_ids that were sampled\n",
    "sampled_hadm_ids_list = sampled_unique_stays.get_column(\"hadm_id\")\n",
    "print(f\"Total number of hadm_ids sampled: {len(sampled_hadm_ids_list)} ({min_hadm_id_group_size} per GT group)\")\n",
    "\n",
    "# 5. Filter the original final_df to keep all rows for the sampled hadm_ids\n",
    "sampled_df = final_df.filter(pl.col(\"hadm_id\").is_in(sampled_hadm_ids_list))\n",
    "\n",
    "print(f\"Shape of the original final DataFrame: {final_df.shape}\")\n",
    "print(f\"Shape of the sampled DataFrame (containing all prompts for sampled IDs): {sampled_df.shape}\")\n",
    "\n",
    "# 6. Verify the distribution of GT_FLAG in the sampled DataFrame (optional but good)\n",
    "#    Count unique hadm_ids per GT_FLAG in the final sampled data\n",
    "print(\"Distribution of unique hadm_ids per GT_FLAG in the sampled DataFrame:\")\n",
    "print(sampled_df.select([\"hadm_id\", \"GT_FLAG\"]).unique(subset=[\"hadm_id\"]).group_by(\"GT_FLAG\").len()) # Added unique() here for safety/clarity in verification\n",
    "\n",
    "# --- Sanity Check: Verify Prompt Count per hadm_id ---\n",
    "\n",
    "run_sanity_check(sampled_df, df_name=\"Sampled_data_with_uniform_ground_truth_distribution\", expected_count=EXPECTED_PROMPT_COUNT)\n",
    "\n",
    "# --- Sanity Check Ends ---\n",
    "\n",
    "\n",
    "# 7. Save the sampled DataFrame using the globally defined path\n",
    "sampled_df.write_csv(SAMPLED_DF_CSV_PATH)\n",
    "print(f\"Sampled DataFrame (by hadm_id) saved as: {SAMPLED_DF_CSV_PATH}\")\n",
    "\n",
    "# --- Sampling Code Ends Here ---\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# --- Splitting the Sampled Data into Train/Val/Test by hadm_id ---\n",
    "\n",
    "print(\"\\n\\n\\n--- Splitting GT-Sampled Data into Train/Val/Test Sets ---\")\n",
    "\n",
    "# Get the unique hadm_ids from the GT-sampled data\n",
    "unique_sampled_ids = sampled_unique_stays.get_column(\"hadm_id\").to_list() # Use the already sampled unique IDs\n",
    "print(f\"Total unique hadm_ids to split: {len(unique_sampled_ids)}\")\n",
    "\n",
    "# Shuffle the unique IDs using the random seed\n",
    "random.shuffle(unique_sampled_ids)\n",
    "print(f\"Shuffled unique hadm_ids using seed {RANDOM_SEED}.\")\n",
    "\n",
    "# Calculate split points based on percentages\n",
    "n_total = len(unique_sampled_ids)\n",
    "n_train = int(TRAIN_SPLIT_PERC * n_total)\n",
    "n_val = int(VAL_SPLIT_PERC * n_total)\n",
    "# n_test = n_total - n_train - n_val # Calculate test size last to avoid rounding errors losing samples\n",
    "\n",
    "# Slice the shuffled list to get IDs for each set\n",
    "train_ids = unique_sampled_ids[:n_train]\n",
    "val_ids = unique_sampled_ids[n_train : n_train + n_val]\n",
    "test_ids = unique_sampled_ids[n_train + n_val :] # The rest go to test\n",
    "\n",
    "print(f\"Split sizes (by hadm_id): Train={len(train_ids)}, Validation={len(val_ids)}, Test={len(test_ids)}\")\n",
    "assert len(train_ids) + len(val_ids) + len(test_ids) == n_total, \"Error: Total IDs after split do not match original count.\"\n",
    "\n",
    "# Filter the main sampled_df to create the final datasets\n",
    "print(\"Filtering DataFrame to create splits...\")\n",
    "train_df = sampled_df.filter(pl.col(\"hadm_id\").is_in(train_ids))\n",
    "val_df = sampled_df.filter(pl.col(\"hadm_id\").is_in(val_ids))\n",
    "test_df = sampled_df.filter(pl.col(\"hadm_id\").is_in(test_ids))\n",
    "\n",
    "print(f\"Resulting DataFrame shapes: Train={train_df.shape}, Validation={val_df.shape}, Test={test_df.shape}\")\n",
    "\n",
    "# --- Run Sanity Checks on Each Split ---\n",
    "run_sanity_check(train_df, \"Train Set\", EXPECTED_PROMPT_COUNT)\n",
    "run_sanity_check(val_df, \"Validation Set\", EXPECTED_PROMPT_COUNT)\n",
    "run_sanity_check(test_df, \"Test Set\", EXPECTED_PROMPT_COUNT)\n",
    "\n",
    "# --- Save the Split Datasets ---\n",
    "print(\"\\nSaving split datasets...\")\n",
    "train_df.write_csv(TRAIN_DF_CSV_PATH)\n",
    "print(f\"Train dataset saved to: {TRAIN_DF_CSV_PATH}\")\n",
    "val_df.write_csv(VAL_DF_CSV_PATH)\n",
    "print(f\"Validation dataset saved to: {VAL_DF_CSV_PATH}\")\n",
    "test_df.write_csv(TEST_DF_CSV_PATH)\n",
    "print(f\"Test dataset saved to: {TEST_DF_CSV_PATH}\")\n",
    "\n",
    "print(\"\\n--- Data Processing and Splitting Complete ---\")\n",
    "\n",
    "# --- Splitiing dataset into train, val, test Code Ends Here\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal_graph2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
